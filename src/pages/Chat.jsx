import { useEffect, useRef, useState } from "react";
import { Send, Mic, Bot, User } from "lucide-react";

// const API_URL = import.meta.env.VITE_API_URL || "http://localhost:5000";
const DEFAULT_CAR_MODEL = "ì•„ë°˜ë–¼";
const API_BASE = "";

/** ì§§ì€ ë¬¸ì¥ì€ ì•Œì•½(Pill) í˜•íƒœë¡œ ë Œë”ë§ */
const isShort = (t) => t.length <= 12 && !t.includes("\n");

/** ì¼ë°˜ ë§í’ì„  */
function Bubble({ me, children }) {
  return (
    <div className={`w-full flex ${me ? "justify-end" : "justify-start"}`}>
      <div
        className={[
          "max-w-[76%] rounded-2xl leading-relaxed shadow-sm border border-white/10",
          "px-4 py-3 text-[18px]",
          me ? "bg-accent/20 text-text" : "bg-white/10 text-text",
        ].join(" ")}
      >
        {children}
      </div>
    </div>
  );
}

/** í”„ë¡œí•„ + ë§í’ì„ . ì§§ì€ ë¬¸ì¥ì€ ì•Œì•½(Pill) */
function Row({ me, text }) {
  const content = isShort(text) ? (
    <div
      className={[
        "px-5 py-2.5 rounded-full text-[18px] font-medium",
        me ? "bg-accent/30 text-text" : "bg-white/10 text-text",
      ].join(" ")}
    >
      {text}
    </div>
  ) : (
    <Bubble me={me}>
      {text.split("\n").map((line, i) => {
        const bullet = line.trim().startsWith("- ");
        return bullet ? (
          <div key={i} className="flex gap-2">
            <span className="mt-[9px] h-[6px] w-[6px] rounded-full bg-sub/80" />
            <span>{line.replace(/^-\\s*/, "").replace(/^-\s*/, "")}</span>
          </div>
        ) : (
          <p key={i} className="whitespace-pre-wrap">{line}</p>
        );
      })}
    </Bubble>
  );

  return (
    <div className={`w-full flex items-center gap-3 ${me ? "justify-end" : ""}`}>
      {!me && (
        <div className="shrink-0 h-8 w-8 rounded-full bg-panel border border-white/10 flex items-center justify-center mt-[2px]">
          <Bot size={16} className="text-sub" />
        </div>
      )}
      {content}
      {me && (
        <div className="shrink-0 h-8 w-8 rounded-full bg-accent/20 flex items-center justify-center mt-[2px]">
          <User size={16} className="text-text" />
        </div>
      )}
    </div>
  );
}

export default function Chat() {
  const [messages, setMessages] = useState([
    { me: false, text: "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\nì˜ˆ: â€˜ì—”ì§„ ê²½ê³ ë“±ì´ ì¼œì¡Œì–´ìš”â€™" },
  ]);
  const [input, setInput] = useState("");
  const [recording, setRecording] = useState(false);
  const [sending, setSending] = useState(false); // í…ìŠ¤íŠ¸ ì „ì†¡ ì¤‘
  const endRef = useRef(null);

  // ====== ìŒì„± ìë™ ì¢…ë£Œ ì„¤ì • ======
  const SILENCE_THRESHOLD = 0.015; // 0~1
  const SILENCE_MS = 1200;         // ë¬´ìŒ ì§€ì† ì‹œ ìë™ ì •ì§€
  const MAX_RECORD_MS = 15000;     // ìµœëŒ€ ë…¹ìŒ ê¸¸ì´

  // ë…¹ìŒ/ë¬´ìŒê°ì§€ ë ˆí¼ëŸ°ìŠ¤
  const mediaRecRef = useRef(null);
  const chunksRef = useRef([]);
  const audioCtxRef = useRef(null);
  const analyserRef = useRef(null);
  const rafRef = useRef(0);
  const lastNonSilentRef = useRef(0);
  const autoStopTimerRef = useRef(null);
  const isStoppingRef = useRef(false);

  useEffect(() => {
    endRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages, sending, recording]);

  // ----- ê³µí†µ: ë°±ì—”ë“œ í˜¸ì¶œ -----
  async function callAsk(question, carModel) {
    // const res = await fetch(`${API_URL}/api/ask`, {
    const res = await fetch(`${API_BASE}/api/ask`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ question, carModel }),
    });
    if (!res.ok) throw new Error(`ASK HTTP ${res.status}`);
    const data = await res.json();
    return data.answer ?? "(ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤)";
  }

  // ----- í…ìŠ¤íŠ¸ ì „ì†¡ (ìë¦¬í‘œì‹œ â€œìƒê° ì¤‘â€¦â€ êµì²´) -----
  const send = async () => {
    const text = input.trim();
    if (!text || sending || recording) return;

    // ì‚¬ìš©ì ë©”ì‹œì§€ + ìë¦¬í‘œì‹œ
    setMessages((prev) => [...prev, { me: true, text }, { me: false, text: "ìƒê° ì¤‘â€¦" }]);
    setInput("");
    setSending(true);

    try {
      const answer = await callAsk(text, DEFAULT_CAR_MODEL);
      setMessages((prev) => {
        const next = [...prev];
        next[next.length - 1] = { me: false, text: answer }; // ìë¦¬í‘œì‹œ êµì²´
        return next;
      });
    } catch (err) {
      setMessages((prev) => {
        const next = [...prev];
        next[next.length - 1] = {
          me: false,
          text:
            "ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì‹¤í–‰ê³¼ VITE_API_URL ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
        };
        return next;
      });
    } finally {
      setSending(false);
    }
  };

  // ===== ìŒì„± ì…ë ¥ =====
  const pickMime = () => {
    if (window.MediaRecorder?.isTypeSupported("audio/ogg;codecs=opus"))
      return "audio/ogg;codecs=opus";
    if (window.MediaRecorder?.isTypeSupported("audio/webm;codecs=opus"))
      return "audio/webm;codecs=opus";
    return "";
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const prefer = pickMime();
      const mr = new MediaRecorder(stream, prefer ? { mimeType: prefer } : undefined);

      chunksRef.current = [];
      isStoppingRef.current = false;

      mr.ondataavailable = (e) => {
        if (e.data && e.data.size) chunksRef.current.push(e.data);
      };

      mr.onstop = async () => {
        // ì •ë¦¬
        if (rafRef.current) cancelAnimationFrame(rafRef.current);
        if (autoStopTimerRef.current) clearTimeout(autoStopTimerRef.current);
        if (audioCtxRef.current) {
          try { await audioCtxRef.current.close(); } catch {}
          audioCtxRef.current = null;
        }
        analyserRef.current = null;

        const type = mr.mimeType || "audio/webm";
        const blob = new Blob(chunksRef.current, { type });

        // ì‚¬ìš©ì ìŒì„± ì „ì†¡ í‘œì‹œ
        setMessages((prev) => [...prev, { me: true, text: "ğŸ¤ (ìŒì„± ë©”ì‹œì§€ ì „ì†¡)" }, { me:false, text:"ìƒê° ì¤‘â€¦" }]);

        const ext = type.includes("ogg") ? "ogg" : type.includes("wav") ? "wav" : "webm";
        const fd = new FormData();
        fd.append("file", blob, `voice.${ext}`);
        fd.append("file", blob, "input.webm"); // ì¶”ê°€í•œê±°

        try {
          // const res = await fetch(`${API_URL}/api/voice`, {
          const res = await fetch(`${API_BASE}/api/voice`, {   
            method: "POST", body: fd 
          });
          if (!res.ok) throw new Error(`VOICE HTTP ${res.status}`);
          const data = await res.json();

          // ìë¦¬í‘œì‹œ êµì²´: ì¸ì‹ ê²°ê³¼ + ë‹µë³€
          setMessages((prev) => {
            const next = [...prev];
            // ë§ˆì§€ë§‰(ìë¦¬í‘œì‹œ) êµì²´
            next[next.length - 1] = { me: false, text: `ğŸ“ ì¸ì‹: ${data.text ?? ""}` };
            // ë‹µë³€ ì¶”ê°€
            next.push({ me: false, text: data.answer || "(ì‘ë‹µ ì—†ìŒ)" });
            return next;
          });
        } catch (err) {
          setMessages((prev) => {
            const next = [...prev];
            next[next.length - 1] = { me: false, text: "ìŒì„± ì „ì†¡ ì‹¤íŒ¨: " + String(err) };
            return next;
          });
        }
      };

      // data ìœ ì‹¤ ë°©ì§€ìš© timeslice
      mr.start(250);
      mediaRecRef.current = mr;
      setRecording(true);

      // ë¬´ìŒ ê°ì§€
      const AudioCtx = window.AudioContext || window.webkitAudioContext;
      audioCtxRef.current = new AudioCtx();
      const source = audioCtxRef.current.createMediaStreamSource(stream);
      analyserRef.current = audioCtxRef.current.createAnalyser();
      analyserRef.current.fftSize = 2048;
      source.connect(analyserRef.current);

      lastNonSilentRef.current = performance.now();

      const detect = () => {
        const a = analyserRef.current;
        if (!a) return;
        const n = a.fftSize;
        const data = new Uint8Array(n);
        a.getByteTimeDomainData(data);

        // RMS(0~1)
        let sum = 0;
        for (let i = 0; i < n; i++) {
          const v = (data[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / n);

        const now = performance.now();
        if (rms > SILENCE_THRESHOLD) lastNonSilentRef.current = now;
        if (now - lastNonSilentRef.current > SILENCE_MS) {
          stopRecording(true);
          return;
        }
        rafRef.current = requestAnimationFrame(detect);
      };
      rafRef.current = requestAnimationFrame(detect);

      // ìµœëŒ€ ë…¹ìŒ ê¸¸ì´ í•˜ë“œìº¡
      autoStopTimerRef.current = setTimeout(() => stopRecording(true), MAX_RECORD_MS);
    } catch (err) {
      setMessages((prev) => [...prev, { me: false, text: "ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”." }]);
      console.error(err);
    }
  };

  const stopRecording = () => {
    const mr = mediaRecRef.current;
    if (!mr || isStoppingRef.current) return;
    isStoppingRef.current = true;
    try {
      try { mr.requestData && mr.requestData(); } catch {}
      if (mr.state !== "inactive") mr.stop();
      mr.stream.getTracks().forEach((t) => t.stop());
    } finally {
      mediaRecRef.current = null;
      setRecording(false);
    }
  };

  return (
    <div className="h-full flex flex-col">
      {/* ìƒë‹¨ í—¤ë” */}
      <header className="px-6 py-3 border-b border-white/10 flex items-center gap-3">
        <div className="h-8 w-8 rounded-xl bg-panel border border-white/10 flex items-center justify-center">
          <Bot size={16} className="text-sub" />
        </div>
        <div className="font-semibold">ì°¨ëŸ‰ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸</div>
        <div className="text-sub text-sm">ì±„íŒ…</div>
      </header>

      {/* ëŒ€í™” ì˜ì—­ */}
      <section className="flex-1 overflow-y-auto px-6 py-5 space-y-6">
        {messages.map((m, i) => (
          <Row key={i} me={m.me} text={m.text} />
        ))}
        <div ref={endRef} />
      </section>

      {/* í•˜ë‹¨ ì…ë ¥ ë°” */}
      <footer className="px-6 pb-6">
        <div className="bg-panel border border-white/10 rounded-full h-14 px-3 flex items-center gap-1">
          {/* ë§ˆì´í¬ ë²„íŠ¼ */}
          <button
            type="button"
            onClick={recording ? () => stopRecording() : startRecording}
            aria-pressed={recording}
            title={recording ? "ë…¹ìŒ ì¤‘ì§€" : "ìŒì„± ì…ë ¥"}
            className={`h-10 w-10 rounded-full flex items-center justify-center transition ${
              recording ? "bg-good/30" : "hover:bg-white/10"
            }`}
          >
            <Mic size={18} className={recording ? "text-good" : "text-sub"} />
          </button>

          <input
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={(e) => {
              if (e.key === "Enter" && !e.shiftKey) {
                e.preventDefault();
                send();
              }
            }}
            placeholder={
              recording ? "ë…¹ìŒ ì¤‘..." : sending ? "ì‘ë‹µ ëŒ€ê¸° ì¤‘..." : "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            }
            disabled={sending || recording}
            className="flex-1 bg-transparent outline-none text-[16px] text-text placeholder:text-sub/70 px-2"
          />

          <button
            onClick={send}
            disabled={sending || recording}
            className={`h-10 w-10 rounded-full ${
              sending ? "bg-accent/50" : "bg-accent hover:opacity-90"
            } text-black flex items-center justify-center font-semibold transition`}
            title="ì „ì†¡"
            aria-label="ì „ì†¡"
          >
            <Send size={16} />
          </button>
        </div>
        <div className="mt-2 text-sub text-xs">
          ì—”í„°í‚¤ë¡œ ì „ì†¡ â€¢ ì¤„ë°”ê¿ˆì€ <span className="text-text">Shift+Enter</span>
        </div>
      </footer>
    </div>
  );
}
